{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "if '../code' not in sys.path: sys.path.append('../code')\n",
      "import mnist_downloader\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnist = mnist_downloader.read_data_sets('../data', one_hot=True)\n",
      "import tensorflow as tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extracting ../data/train-images-idx3-ubyte.gz\n",
        "Extracting"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ../data/train-labels-idx1-ubyte.gz\n",
        "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
        "Extracting"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ../data/t10k-labels-idx1-ubyte.gz\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data Set                 x                        y                        \n",
        "validation               (5000, 784)              (5000, 10)               \n",
        "train                    (55000, 784)             (55000, 10)              \n",
        "test                     (10000, 784)             (10000, 10)              \n",
        "\n",
        "x float32 y float64\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# https://www.tensorflow.org/versions/0.6.0/tutorials/mnist/pros/index.html\n",
      "\n",
      "# Softmax regression\n",
      "# TODO make a softmax module with smarter training\n",
      "x = tf.placeholder(\"float\", shape=[None, 784]) # any batch size on flattened pixel values\n",
      "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
      "W = tf.Variable(tf.random_normal([784,10]))\n",
      "b = tf.Variable(tf.random_normal([10]))\n",
      "\n",
      "# Vectorized softmax on entire batch after dot product\n",
      "unscaled_logit = tf.matmul(x, W) + b\n",
      "y = tf.nn.softmax(unscaled_logit)\n",
      "# Loss function and hard-coded training\n",
      "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(unscaled_logit, y_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global_step = tf.Variable(0, trainable=False)\n",
      "initial_learning_rate, decay_fraction, decay_period = 0.01, 0.95, 10000 # TODO better values here\n",
      "learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
      "                                           decay_period, decay_fraction, staircase=False)\n",
      "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy, global_step=global_step)\n",
      "\n",
      "def eval_ds(ds):\n",
      "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
      "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
      "    return 1 - accuracy.eval(feed_dict={x: ds.images, y_: ds.labels})\n",
      "\n",
      "sess = tf.InteractiveSession()\n",
      "\n",
      "sess.run(tf.initialize_all_variables())\n",
      "mnist.train.reset_epoch_count()\n",
      "\n",
      "epochs = 0\n",
      "NUM_EPOCHS = 100 # > 0\n",
      "UPDATE_COARSENESS = 5 # >= 0\n",
      "BATCH_SIZE = 50 # > 0\n",
      "MAX_STEPS_BACKWARD = 3\n",
      "SAVE_PATH = '/tmp/tf-mnist-batch-sgd.ckpt'\n",
      "\n",
      "saver = tf.train.Saver()\n",
      "\n",
      "best_model = None\n",
      "best_validation = np.inf\n",
      "\n",
      "while epochs < NUM_EPOCHS:\n",
      "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
      "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
      "    if mnist.train.epochs_completed > epochs:\n",
      "        epochs = mnist.train.epochs_completed\n",
      "        \n",
      "        if UPDATE_COARSENESS and epochs % UPDATE_COARSENESS == 0:\n",
      "            valid_err = eval_ds(mnist.validation)\n",
      "            print('Epoch {} error {}'.format(epochs, valid_err))\n",
      "            if valid_err > best_validation: break\n",
      "            best_validation = valid_err\n",
      "            best_model = saver.save(sess, SAVE_PATH)\n",
      "            \n",
      "        \n",
      "print('Halted at epoch {}/{} with best validation model error {}'\n",
      "      .format(epochs, NUM_EPOCHS, best_validation))\n",
      "saver.restore(sess, best_model)\n",
      "\n",
      "print('Test error', eval_ds(mnist.test))\n",
      "\n",
      "sess.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5 error 0.08960002660751343\n",
        "Epoch 10 error 0.08539998531341553"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 15 error 0.09219998121261597"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Halted at epoch 15/100 with best validation model error 0.08539998531341553\n",
        "Test error"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0850999951363\n"
       ]
      }
     ],
     "prompt_number": 18
    }
   ],
   "metadata": {}
  }
 ]
}