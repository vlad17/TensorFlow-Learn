{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "if '../code' not in sys.path: sys.path.append('../code')\n",
      "import mnist_downloader\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, test = mnist_downloader.read_data_sets('../data', one_hot=True)\n",
      "import tensorflow as tf\n",
      "\n",
      "from data_set import DataSet\n",
      "\n",
      "print() # TODO is there a package for this?\n",
      "cols = ['Data Set', 'x', 'y']\n",
      "def printtbl(ls): print(''.join(str(i).ljust(25) for i in ls))\n",
      "printtbl(cols)\n",
      "printtbl(['train', train.x.shape, train.y.shape])\n",
      "printtbl(['test', test.x.shape, test.y.shape])\n",
      "print()\n",
      "print('x {!s} y {!s}'.format(train.x.dtype, train.y.dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extracting ../data/train-images-idx3-ubyte.gz\n",
        "Extracting"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ../data/train-labels-idx1-ubyte.gz\n",
        "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
        "Extracting"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ../data/t10k-labels-idx1-ubyte.gz\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data Set                 x                        y                        \n",
        "train                    (60000, 784)             (60000, 10)              \n",
        "test                     (10000, 784)             (10000, 10)              \n",
        "\n",
        "x float32 y float32\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# https://www.tensorflow.org/versions/0.6.0/tutorials/mnist/pros/index.html\n",
      "\n",
      "# Softmax regression\n",
      "# TODO make a softmax module with smarter training\n",
      "x = tf.placeholder(\"float\", shape=[None, 784]) # any batch size on flattened pixel values\n",
      "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
      "W = tf.Variable(tf.random_normal([784,10]))\n",
      "b = tf.Variable(tf.random_normal([10]))\n",
      "\n",
      "# Vectorized softmax on entire batch after dot product\n",
      "unscaled_logit = tf.matmul(x, W) + b\n",
      "y = tf.nn.softmax(unscaled_logit)\n",
      "# Loss function and hard-coded training\n",
      "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(unscaled_logit, y_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global_step = tf.Variable(0, trainable=False)\n",
      "initial_learning_rate, decay_fraction, decay_period = 0.01, 0.95, 10000 # TODO better values here\n",
      "learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
      "                                           decay_period, decay_fraction, staircase=False)\n",
      "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy, global_step=global_step)\n",
      "\n",
      "def eval_ds(ds):\n",
      "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
      "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
      "    return 1 - accuracy.eval(feed_dict={x: ds.x, y_: ds.y})\n",
      "\n",
      "sess = tf.InteractiveSession()\n",
      "\n",
      "NUM_EPOCHS = 100\n",
      "NUM_FOLDS = 4\n",
      "UPDATE_COARSENESS = 5\n",
      "BATCH_SIZE = 50\n",
      "SAVE_PATH = '/tmp/tf-mnist-batch-sgd.ckpt'\n",
      "\n",
      "saver = tf.train.Saver()\n",
      "\n",
      "best_model = None\n",
      "best_validation = np.inf\n",
      "best_epoch = None\n",
      "best_fold = 0\n",
      "\n",
      "# TODO does cross validation exist already?\n",
      "# Cross validate on random restarts\n",
      "for fold, (train, validate) in enumerate(train.cross_validation(NUM_FOLDS)):\n",
      "    fold += 1 # 1-index\n",
      "    print('Starting fold {}'.format(fold))\n",
      "    sess.run(tf.initialize_all_variables())\n",
      "    best_in_fold_validation = np.inf\n",
      "    for epoch in range(NUM_EPOCHS):\n",
      "        epoch += 1 # TODO better 1-index?    \n",
      "        for batch in train.new_epoch(BATCH_SIZE):\n",
      "            train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
      "        if epoch == NUM_EPOCHS or UPDATE_COARSENESS and epoch % UPDATE_COARSENESS == 0:\n",
      "            valid_err = eval_ds(validate)\n",
      "            print('  Epoch {:3} error {}'.format(epoch, valid_err))\n",
      "            if valid_err > best_in_fold_validation: break\n",
      "            best_in_fold_validation = valid_err\n",
      "            if valid_err > best_validation: continue\n",
      "            best_validation = valid_err\n",
      "            best_epoch = epoch\n",
      "            best_fold = fold\n",
      "            best_model = saver.save(sess, SAVE_PATH)\n",
      "            \n",
      "print('Fold {}/{} epoch {}/{} with best validation error {}'\n",
      "      .format(best_fold, NUM_FOLDS, best_epoch, NUM_EPOCHS, best_validation))\n",
      "        \n",
      "saver.restore(sess, best_model)\n",
      "\n",
      "print('Test error', eval_ds(test))\n",
      "sess.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting fold 1\n",
        "  Epoch   5 error 0.10562962293624878"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  10 error 0.09474074840545654"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  15 error 0.09696298837661743"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting fold 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch   5 error 0.10992592573165894"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  10 error 0.10111111402511597"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  15 error 0.09874075651168823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  20 error 0.09777778387069702"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  25 error 0.09644442796707153"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  30 error 0.09066665172576904"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  35 error 0.09274071455001831"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting fold 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch   5 error 0.10637038946151733"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  10 error 0.10140740871429443"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  15 error 0.09570372104644775"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  20 error 0.0976296067237854"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting fold 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch   5 error 0.1061481237411499"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  10 error 0.09207409620285034"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  15 error 0.0882222056388855"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  20 error 0.08703702688217163"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Epoch  25 error 0.08955556154251099"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold 4/4 epoch 20/100 with best validation model error 0.08703702688217163\n",
        "Test error"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0848000049591\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}